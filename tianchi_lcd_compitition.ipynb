{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# 固定seed，从而使得训练模型中的随机数相同，可以重现对应的训练结果\n",
    "np.random.seed(1)\n",
    "\n",
    "import keras\n",
    "from sklearn import preprocessing as pro\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为0的数值被视为有效的sigma门限值，超过该值，将该值替换为mean\n",
    "sigma_threshold_of_zero=2\n",
    "# training数据中作为1/K作为vaild数据\n",
    "K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_datasets = pd.read_excel('train.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据中比较大的问题：\n",
    "- 有相当的数据有很多的zero，需要确定是否是数值的缺失\n",
    "  - 部分数据是整列都是0，对于这些数据，这些数据列可以去掉，不参与学习\n",
    "  - 部分数据列大部分数据都有，少数为0，并且0的不在大概率分布里面，讲0设置为对应的mean\n",
    "  - 部分数据和其它列完全相同，可以去掉重复的数据列（但是不能跨越不同的工具列）\n",
    "  - 部分数据的为缺失，此时设置为该列的mean\n",
    "- 有部分数据有缺失值，需要确定如何处理对应的数据\n",
    "  - 目前缺失的数据\n",
    "- 有部分的column的数据是重复的，可以去除对应的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_train_dataset(df):\n",
    "    # 去除重复的columns\n",
    "    df_tmp = df.T.drop_duplicates().T\n",
    "    print('after duplicates columns removed:{} columns {} row'.format(len(df_tmp.columns),len(df_tmp)))\n",
    "    # 去除名为Tools的列，因为目前的数据较少，不考虑流水线中不同阶段不同的机器对最终数据的影响。\n",
    "    df_tmp = df_tmp.filter(regex='^(?!([Tt][Oo][Oo][Ll]))', axis=1)\n",
    "    print('after machine id columns removed:{} columns {} row'.format(len(df_tmp.columns), len(df_tmp)))\n",
    "    # 去除ID columns，通过tranpose，index变成了column\n",
    "    df_tmp.drop(['ID'],axis=1,inplace=True)\n",
    "    droped_columns = []\n",
    "    mean_dict = {}\n",
    "    std_dict = {}\n",
    "    zero_update_dict = {}\n",
    "    # 对每一列的数据进行处理\n",
    "    for col in df_tmp.columns:\n",
    "        col_tmp = df_tmp[col]\n",
    "        # 数据中有时间string的数据，格式为%Y%m%d%M%S%f，\n",
    "        if re.match('^2017[0-9]{10}',str(df_tmp[col].iloc[0])) or re.match('^2017[0-1][0-9][0-3][0-9]',str(df_tmp[col].iloc[0])):\n",
    "            droped_columns.append(col)\n",
    "            continue\n",
    "        # 计算Mean和std的时候忽略为0的元素先\n",
    "        non_zeros = col_tmp.iloc[col_tmp.nonzero()]\n",
    "        mean = non_zeros.mean()\n",
    "        std = non_zeros.std()\n",
    "        if math.isnan(mean) or std == 0:\n",
    "            # 只有0和NaN的列求Mean将返回Nan，这种数据没有用，可以直接删除\n",
    "            droped_columns.append(col)\n",
    "            continue\n",
    "        # 0 在 2 sigma之内，那么0为正常值，此时需要重新计算\n",
    "        if mean - std * sigma_threshold_of_zero < 0  and mean + std * sigma_threshold_of_zero > 0:\n",
    "            mean = df_tmp[col].mean()\n",
    "            mean_dict[col] = mean\n",
    "            std_dict[col] = df_tmp[col].std()\n",
    "            zero_update_dict[col] = False\n",
    "            # 使用新计算的Mean替换空值\n",
    "            df_tmp[col].replace([np.NaN], mean, inplace=True)\n",
    "        else:\n",
    "            # 使用mean替换nan和zero值\n",
    "            df_tmp[col].replace([0,np.NaN], mean, inplace=True)\n",
    "            mean_dict[col] = mean\n",
    "            std_dict[col] = std\n",
    "            zero_update_dict[col] = True\n",
    "    # 删除Mean为Nan或者标准差为0的数据\n",
    "    df_tmp.drop(droped_columns,axis=1,inplace=True)\n",
    "    print('after column data cleaned:{} columns {} rows'.format(len(df_tmp.columns),len(df_tmp)))\n",
    "\n",
    "    return df_tmp,mean_dict,zero_update_dict,std_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after duplicates columns removed:3457 columns 500 row\n",
      "after machine id columns removed:3444 columns 500 row\n",
      "after column data cleaned:3210 columns 500 rows\n"
     ]
    }
   ],
   "source": [
    "# 从已有的文件读取或者重新处理该数据\n",
    "raw_train_X_pd = raw_train_datasets.drop(labels=['Y'],axis=1)\n",
    "train_X_pd,mean_dict,zero_update_dict,std_dict = preprocess_train_dataset(raw_train_X_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data with 8028 columns 100 rows cleaned result 3210 columns 100 rows\n",
      "test_data with 8028 columns 121 rows cleaned result 3210 columns 121 rows\n"
     ]
    }
   ],
   "source": [
    "# 预处理test数据集\n",
    "raw_testA = pd.read_excel('testa.xlsx')\n",
    "raw_testB = pd.read_excel('testb.xlsx')\n",
    "\n",
    "def process_test_data(test_data, tmp_file=None):\n",
    "    tmp_df = test_data.copy()\n",
    "    # 去掉在Trainning data中去除的数据\n",
    "    tmp_df_columns = tmp_df.columns.tolist()\n",
    "    train_x_columns = train_X_pd.columns.tolist()\n",
    "    droped_columns = [x for x in tmp_df_columns if x  not in train_x_columns]\n",
    "    tmp_df.drop(droped_columns, axis=1,inplace=True)\n",
    "    extra_columns = []\n",
    "    # 按照training data中的mean和zero更新到情况处理test data中的zero和NaN\n",
    "    for col in tmp_df.columns:\n",
    "        if col not in mean_dict:\n",
    "            extra_columns.append(col)\n",
    "            continue\n",
    "        if zero_update_dict[col]:\n",
    "            tmp_df[col].replace([0,np.NaN], mean_dict[col], inplace=True)\n",
    "        else:\n",
    "            tmp_df[col].replace([np.NaN], mean_dict[col], inplace=True)\n",
    "    \n",
    "    # todo:测试数据中依然有数据缺失造成的为0的数据，和正常值有比较大的区别，为了提高预测的准确率，需要对这些数据进行处理。\n",
    "    # 对每一列的数据进行处理\n",
    "    for col in tmp_df.columns:\n",
    "        col_tmp = tmp_df[col]\n",
    "        # 计算Mean和std的时候忽略为0的元素先\n",
    "        non_zeros = col_tmp.iloc[col_tmp.nonzero()]\n",
    "        mean = non_zeros.mean()\n",
    "        std = non_zeros.std()\n",
    "        # 0 不在3个标准差内，那么将这些0改为对应的mean值\n",
    "        if mean + std * 3 < 0  or mean - std * 3 > 0:\n",
    "            # 使用mean替换zero值\n",
    "            tmp_df[col].replace([0], mean, inplace=True)\n",
    "    if tmp_file is not None:\n",
    "        tmp_df.to_excel(tmp_file)        \n",
    "    print(\"test_data with {} columns {} rows cleaned result {} columns {} rows\".format(\n",
    "        len(test_data.columns),len(test_data),len(tmp_df.columns),len(tmp_df)))\n",
    "    \n",
    "    return tmp_df \n",
    "\n",
    "testA_pd = process_test_data(raw_testA,tmp_file='tmpA.xlsx')\n",
    "testB_pd = process_test_data(raw_testB,tmp_file='tmpB.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid X shape (100, 3210) Y shape train X shape (100,) Y shape (400, 3210)\n",
      "testA shape (100, 3210) testB shape (121, 3210)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_Y_whole = raw_train_datasets['Y'].values\n",
    "train_X_whole = train_X_pd.values\n",
    "# 因为test数据有异常的数据，尝试合并所有的数据级之后使用nor\n",
    "all_data = pd.concat([train_X_pd,testA_pd,testB_pd])\n",
    "# 对数据进行Normalization，保留scaler，用以对test数据Normalization\n",
    "scaler = MinMaxScaler().fit(all_data.values)\n",
    "normalized_train_X = scaler.transform(train_X_whole)\n",
    "index_array = np.arange(normalized_train_X.shape[0])\n",
    "np.random.shuffle(index_array)\n",
    "# 对数据进行切割\n",
    "valid_num = normalized_train_X.shape[0]//K\n",
    "valid_X = normalized_train_X[index_array[0:valid_num],:];\n",
    "valid_Y = train_Y_whole[index_array[0:valid_num]]\n",
    "train_X = normalized_train_X[index_array[valid_num:],:]\n",
    "train_Y = train_Y_whole[index_array[valid_num:]]\n",
    "print('valid X shape {} Y shape train X shape {} Y shape {}'.format(valid_X.shape, valid_Y.shape, train_X.shape,train_Y.shape))\n",
    "\n",
    "# 对测试数据集进行normalization\n",
    "testA = scaler.transform(testA_pd.values)\n",
    "testB = scaler.transform(testB_pd.values)\n",
    "print(\"testA shape {} testB shape {}\".format(testA.shape, testB.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# 学习相关的参数\n",
    "epochs_num=2\n",
    "batch_size = 32\n",
    "\n",
    "def show_history(history,model_name):\n",
    "    acc = history.history['mean_absolute_error']\n",
    "    val_acc = history.history['val_mean_absolute_error']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training mae')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation mae')\n",
    "    plt.title('{} Training and validation accuracy'.format(model_name))\n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss'.format(model_name))\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv1d_model(conv1_k_size=11,conv1_num=32,conv2_k_size=7,conv2_num=16,dense_num=64,pool=2,optimizer='adam',dropout=False,droprate=0.4):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(conv1_num,conv1_k_size,padding='valid',input_shape=(train_X.shape[1],1)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool,padding='valid'))\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(droprate))\n",
    "    model.add(layers.Conv1D(conv2_num,conv2_k_size,padding='valid'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling1D(pool,padding='valid'))\n",
    "    if dropout:\n",
    "        model.add(layers.Dropout(droprate))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(dense_num))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    if optimizer is not None:\n",
    "        model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    else:\n",
    "        model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要同时运行不同的模型，不同的参数，执行一定批次，测试对应的效果，并且执行对应的效果:\n",
    "1. 初步确认使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make models ready\n",
    "model_array = []\n",
    "\n",
    "m1 = {}\n",
    "m1['name'] = 'conv1'\n",
    "m1['desc'] = 'adam conv1_11x32 conv2_7x16 dense_64 dropout None pool 2'\n",
    "m1['model'] = build_conv1d_model()\n",
    "m1['batch_size'] = 32\n",
    "model_array.append(m1)\n",
    "\n",
    "m10={}\n",
    "m10['name'] = 'conv1_bs64'\n",
    "m10['desc'] = 'adam conv1_11x32 conv2_7x16 dense_64 dropout None pool 2'\n",
    "m10['model'] = build_conv1d_model()\n",
    "m10['batch_size'] = 64\n",
    "model_array.append(m10)\n",
    "\n",
    "m11={}\n",
    "m11['name'] = 'conv1_dropout_0.3'\n",
    "m11['desc'] = 'adam conv1_11x32 conv2_7x16 dense_64 dropout 0.3 pool 2'\n",
    "m11['model'] = build_conv1d_model(dropout=True, droprate=0.3)\n",
    "m11['batch_size'] = 32\n",
    "model_array.append(m11)\n",
    "\n",
    "m12={}\n",
    "m12['name'] = 'conv1_dropout_0.6'\n",
    "m12['desc'] = 'adam conv1_11x32 conv2_7x16 dense_64 dropout 0.6 pool 2'\n",
    "m12['model'] = build_conv1d_model(dropout=True, droprate=0.6)\n",
    "m12['batch_size'] = 32\n",
    "model_array.append(m12)\n",
    "\n",
    "m2={}\n",
    "m2['name'] = 'conv2' \n",
    "m2['desc'] = 'nadam con1_23x16 conv_11x32 dense_32 dropout None pool 3'\n",
    "m2['batch_size'] = 32\n",
    "m2['model'] = build_conv1d_model(\n",
    "    conv1_k_size = 23, \n",
    "    conv1_num=16, \n",
    "    conv2_k_size=11,\n",
    "    conv2_num=32,\n",
    "    pool=3,\n",
    "    dense_num=32,\n",
    "    optimizer='nadam'\n",
    ")\n",
    "model_array.append(m2)\n",
    "\n",
    "m21={}\n",
    "m21['name'] = 'conv2_dropout_0.3' \n",
    "m21['desc'] = 'nadam con1_23x16 conv_11x32 dense_32 dropout dropout 0.3 pool 3'\n",
    "m21['batch_size'] = 32\n",
    "m21['model'] = build_conv1d_model(\n",
    "    conv1_k_size = 23, \n",
    "    conv1_num=16, \n",
    "    conv2_k_size=11,\n",
    "    conv2_num=32,\n",
    "    pool=3,\n",
    "    dense_num=32,\n",
    "    optimizer='nadam',\n",
    "    dropout=True,\n",
    "    droprate=0.3\n",
    ")\n",
    "model_array.append(m21)\n",
    "\n",
    "m22={}\n",
    "m22['name'] = 'conv2_dropout_0.6' \n",
    "m22['desc'] = 'nadam con1_23x16 conv_11x32 dense_32 dropout dropout 0.6 pool 3'\n",
    "m22['batch_size'] = 32\n",
    "m22['model'] = build_conv1d_model(\n",
    "    conv1_k_size = 23, \n",
    "    conv1_num=16, \n",
    "    conv2_k_size=11,\n",
    "    conv2_num=32,\n",
    "    pool=3,\n",
    "    dense_num=32,\n",
    "    optimizer='nadam',\n",
    "    dropout=True,\n",
    "    droprate=0.6\n",
    ")\n",
    "model_array.append(m22)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多个模型并行运行\n",
    "鉴于模型不是很复杂，计算量不是很大，所以可以多个模型一起并行运行那个，从中间找出性能最好的模型：\n",
    "- 多个模型增加为数组，一次运行每个模型\n",
    "- 保存每个模型和模型学习到的weights\n",
    "- 保存对应的预测结果\n",
    "- 写入所有模型的对应的性能指标（train/valid的loss和acc）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start to training 3_fold on model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_153 (Conv1D)          (None, 3200, 32)          384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 3200, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_229 (Activation)  (None, 3200, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 1600, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 1594, 16)          3600      \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 1594, 16)          64        \n",
      "_________________________________________________________________\n",
      "activation_230 (Activation)  (None, 1594, 16)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 797, 16)           0         \n",
      "_________________________________________________________________\n",
      "flatten_77 (Flatten)         (None, 12752)             0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 64)                816192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_231 (Bat (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "activation_231 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 820,689\n",
      "Trainable params: 820,465\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "training on 3_fold_0\n",
      "Train on 334 samples, validate on 166 samples\n",
      "Epoch 1/2\n",
      "334/334 [==============================] - 10s 30ms/step - loss: 6.6938 - mean_absolute_error: 2.4118 - val_loss: 6.5122 - val_mean_absolute_error: 2.5428\n",
      "Epoch 2/2\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 3.8865 - mean_absolute_error: 1.8622 - val_loss: 5.6630 - val_mean_absolute_error: 2.3714\n",
      "3_fold_0 CV model Train Y min 2.3268455638817764 max 3.454555830692319 mean 2.838961897422923 std 0.20478033053724867\n",
      "3_fold_0 CV resultA min 0.2295665442943573 max 0.6397817134857178 mean 0.39443764090538025 std 0.0804283395409584\n",
      "3_fold_0 resultB min 0.18690605461597443 max 0.6661863923072815 mean 0.4200868010520935 std 0.09858077764511108\n",
      "3_fold_0 CV                 train_loss  val_loss  train_acc   val_acc  min_testA_Y  \\\n",
      "model_3_fold_0    6.693761  6.693761   2.136992  2.457141     0.229567   \n",
      "\n",
      "                max_testA_Y  testA_Y_mean  test_A_std  min_testB_Y  \\\n",
      "model_3_fold_0     0.639782      0.394438    0.080428     0.186906   \n",
      "\n",
      "                max_testB_Y  testB_Y_mean  test_B_std  min_train_Y  \\\n",
      "model_3_fold_0     0.666186      0.420087    0.098581     2.326846   \n",
      "\n",
      "                max_train_Y  train_Y_mean  train_Y_std  \n",
      "model_3_fold_0     3.454556      2.838962      0.20478  \n",
      "training on 3_fold_1\n",
      "Train on 334 samples, validate on 166 samples\n",
      "Epoch 1/2\n",
      "334/334 [==============================] - 9s 26ms/step - loss: 6.1026 - mean_absolute_error: 2.3582 - val_loss: 5.5649 - val_mean_absolute_error: 2.3456\n",
      "Epoch 2/2\n",
      "334/334 [==============================] - 4s 11ms/step - loss: 3.5981 - mean_absolute_error: 1.8154 - val_loss: 5.8985 - val_mean_absolute_error: 2.4122\n",
      "3_fold_1 CV model Train Y min 2.3268455638817764 max 3.454555830692319 mean 2.838961897422923 std 0.20478033053724867\n",
      "3_fold_1 CV resultA min 0.15004192292690277 max 0.7875720858573914 mean 0.4724518656730652 std 0.13567237555980682\n",
      "3_fold_1 resultB min 0.09019783139228821 max 0.7991991639137268 mean 0.4856693148612976 std 0.127111554145813\n",
      "perf 2 3_fold_1 statis later added                 train_loss  val_loss  train_acc   val_acc  min_testA_Y  \\\n",
      "model_3_fold_1    6.102615  6.102615   2.086822  2.378888     0.150042   \n",
      "\n",
      "                max_testA_Y  testA_Y_mean  test_A_std  min_testB_Y  \\\n",
      "model_3_fold_1     0.787572      0.472452    0.135672     0.090198   \n",
      "\n",
      "                max_testB_Y  testB_Y_mean  test_B_std  min_train_Y  \\\n",
      "model_3_fold_1     0.799199      0.485669    0.127112     2.326846   \n",
      "\n",
      "                max_train_Y  train_Y_mean  train_Y_std  \n",
      "model_3_fold_1     3.454556      2.838962      0.20478  \n",
      "training on 3_fold_2\n",
      "Train on 332 samples, validate on 168 samples\n",
      "Epoch 1/2\n",
      "332/332 [==============================] - 9s 27ms/step - loss: 6.0973 - mean_absolute_error: 2.3036 - val_loss: 6.6697 - val_mean_absolute_error: 2.5728\n",
      "Epoch 2/2\n",
      "332/332 [==============================] - 4s 11ms/step - loss: 3.4498 - mean_absolute_error: 1.7456 - val_loss: 5.7305 - val_mean_absolute_error: 2.3822\n",
      "3_fold_2 CV model Train Y min 2.3268455638817764 max 3.454555830692319 mean 2.838961897422923 std 0.20478033053724867\n",
      "3_fold_2 CV resultA min 0.15135827660560608 max 0.813249945640564 mean 0.5368332266807556 std 0.12591828405857086\n",
      "3_fold_2 resultB min 0.26720577478408813 max 0.8280161023139954 mean 0.5170645117759705 std 0.12001077830791473\n",
      "perf 3 3_fold_2 statis later added                 train_loss  val_loss  train_acc  val_acc  min_testA_Y  \\\n",
      "model_3_fold_2    6.097343  6.097343   2.024594  2.47749     0.151358   \n",
      "\n",
      "                max_testA_Y  testA_Y_mean  test_A_std  min_testB_Y  \\\n",
      "model_3_fold_2      0.81325      0.536833    0.125918     0.267206   \n",
      "\n",
      "                max_testB_Y  testB_Y_mean  test_B_std  min_train_Y  \\\n",
      "model_3_fold_2     0.828016      0.517065    0.120011     2.326846   \n",
      "\n",
      "                max_train_Y  train_Y_mean  train_Y_std  \n",
      "model_3_fold_2     3.454556      2.838962      0.20478  \n",
      "training on 3_fold_3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_whole_Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-48e36f1a6ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# 最后一次使用所有的数据进行训练，不使用validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mcv_train_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_train_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_train_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_train_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mcv_train_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_whole_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# 开始训练模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_whole_Y' is not defined"
     ]
    }
   ],
   "source": [
    "#使用k_fold CV来改进模型的情况\n",
    "K=3\n",
    "\n",
    "index_array = np.arange(normalized_train_X.shape[0])\n",
    "np.random.shuffle(index_array)\n",
    "num_per_cv = normalized_train_X.shape[0]//K\n",
    "cv_X_array = []\n",
    "cv_Y_array = []\n",
    "\n",
    "# 使用同一个model训练\n",
    "cv_models = []\n",
    "# 生成k_fold CV数组\n",
    "for index in range(K):\n",
    "    if index == K - 1:\n",
    "        cv_X = normalized_train_X[num_per_cv * index:,:]\n",
    "        cv_Y = train_Y_whole[num_per_cv * index:]\n",
    "    else:\n",
    "        cv_X = normalized_train_X[num_per_cv * index:num_per_cv * (index + 1),:]\n",
    "        cv_Y = train_Y_whole[num_per_cv * index:num_per_cv * (index + 1)]\n",
    "    cv_X_array.append(cv_X)\n",
    "    cv_Y_array.append(cv_Y)\n",
    "for index in range(K+1):\n",
    "    # 为每个cv创建相同的model，进行训练\n",
    "    model = build_conv1d_model()\n",
    "    cv_models.append(model)\n",
    "print('start to training {}_fold on model'.format(K))\n",
    "cv_models[0].summary()\n",
    "\n",
    "testA_X = np.reshape(testA, (testA.shape[0], testB.shape[1], 1))\n",
    "testB_X = np.reshape(testB, (testB.shape[0], testB.shape[1], 1))\n",
    "perf = pd.DataFrame()\n",
    "\n",
    "# 使用k_fold来训练模型\n",
    "for index in range(K + 1):\n",
    "    print('training on {}_fold_{}'.format(K, index))\n",
    "    cv_X_tmp = []\n",
    "    cv_Y_tmp = []\n",
    "    if index < K:\n",
    "        cv_X_tmp = cv_X_array[0:index] + cv_X_array[index+1:]\n",
    "        cv_train_X = np.concatenate(cv_X_tmp)\n",
    "        cv_train_X = np.reshape(cv_train_X, (cv_train_X.shape[0],cv_train_X.shape[1],1))\n",
    "        cv_Y_tmp = cv_Y_array[0:index] + cv_Y_array[index+1:]\n",
    "        cv_train_Y = np.concatenate(cv_Y_tmp)\n",
    "        validation_X = np.reshape(cv_X_array[index],(cv_X_array[index].shape[0],cv_X_array[index].shape[1],1))\n",
    "        validation_data = (validation_X,cv_Y_array[index])\n",
    "    else:\n",
    "        # 最后一次使用所有的数据进行训练，不使用validation data\n",
    "        cv_train_X = np.reshape(normalized_train_X,(normalized_train_X.shape[0], normalized_train_X.shape[1],1))\n",
    "        cv_train_Y = train_whole_Y\n",
    "        validation_data = None\n",
    "    # 开始训练模型\n",
    "    history = cv_models[index].fit(\n",
    "        cv_train_X,\n",
    "        cv_train_Y,\n",
    "        epochs = epochs_num,\n",
    "        batch_size = batch_size,\n",
    "        validation_data = validation_data\n",
    "    )\n",
    "    # 保存模型\n",
    "    json_string = cv_models[index].to_json()\n",
    "    f = open('cv_model_{}_of_{}_folds.json'.format(index, K),'w')\n",
    "    f.write(json_string)\n",
    "    f.close()\n",
    "    # 保存当前训练的参数\n",
    "    cv_models[index].save_weights('cv_model_weights_{}_bs_{}.h5'.format(m['name'],m['batch_size']))\n",
    "    \n",
    "    # 进行预测，并且保留对应的数据\n",
    "    testA_Y = cv_models[index].predict(testA_X, batch_size=batch_size)\n",
    "    testB_Y = cv_models[index].predict(testB_X, batch_size=batch_size)\n",
    "    # 和trainning的数据进行对比，检查test数据的合理性\n",
    "    print('{}_fold_{} CV model Train Y min {} max {} mean {} std {}'.format(K,index,np.min(train_Y),np.max(train_Y),np.mean(train_Y),np.std(train_Y)))\n",
    "    print('{}_fold_{} CV resultA min {} max {} mean {} std {}'.format(K,index,np.min(testA_Y),np.max(testA_Y),np.mean(testA_Y),np.std(testA_Y)))\n",
    "    print('{}_fold_{} resultB min {} max {} mean {} std {}'.format(K,index,np.min(testB_Y),np.max(testB_Y),np.mean(testB_Y),np.std(testB_Y)))\n",
    "    # 合并数据结果，并且写入测试结果\n",
    "    resultA = pd.DataFrame({'ID':raw_testA['ID'].values,'Y':testA_Y.ravel()})\n",
    "    resultA.to_csv('resultA_{}_fold_{}.csv'.format(K,index), header=False,index=False)\n",
    "    resultB = pd.DataFrame({'ID':raw_testB['ID'].values,'Y':testB_Y.ravel()})\n",
    "    resultB.to_csv('resultB_{}_fold_{}.csv'.format(K,index), header=False,index=False)\n",
    "    if index < K:\n",
    "        # 去最后10个poch的平均值作为mean来评价本次模型训练的情况\n",
    "        train_loss_mean = np.mean(history.history['loss'][-11:-1])\n",
    "        val_loss_mean = np.mean(history.history['loss'][-11:-1])\n",
    "        train_acc_mean = np.mean(history.history['mean_absolute_error'])\n",
    "        val_acc_mean = np.mean(history.history['val_mean_absolute_error'])\n",
    "    else:\n",
    "        # 最后一次训练没有使用\n",
    "        train_loss_mean,val_loss_mean,train_acc_mean,val_acc_mean = 0.,0.,0.,0.\n",
    "    # 保留本次模型运行的结果\n",
    "    statis = pd.DataFrame(\n",
    "        [[train_loss_mean, val_loss_mean,train_acc_mean,val_acc_mean,np.min(testA_Y),np.max(testA_Y),np.mean(testA_Y),np.std(testA_Y), \\\n",
    "        np.min(testB_Y),np.max(testB_Y),np.mean(testB_Y),np.std(testB_Y),np.min(train_Y),np.max(train_Y),np.mean(train_Y),np.std(train_Y)]],\n",
    "        columns=['train_loss','val_loss','train_acc','val_acc','min_testA_Y','max_testA_Y','testA_Y_mean','test_A_std','min_testB_Y','max_testB_Y','testB_Y_mean','test_B_std',\\\n",
    "                 'min_train_Y','max_train_Y','train_Y_mean','train_Y_std'],\n",
    "        index=['model_{}_fold_{}'.format(K,index)])\n",
    "    if perf.empty:\n",
    "        perf = statis\n",
    "        print('{}_fold_{} CV {}'.format(K,index,statis))\n",
    "    else:\n",
    "        perf = pd.concat([perf,statis])\n",
    "        print('perf {} {}_fold_{} statis later added {}'.format(len(perf), K, index, statis))\n",
    "    # 将性能信息写入到本地文件\n",
    "    perf.to_excel('cv_modle_performance_{}_fold.xlsx'.format(K))\\\n",
    "# 平均K_fold的weight，作为我们模型最终的weights\n",
    "weights = cv_models[K].get_weights()\n",
    "for index in range(K):\n",
    "    weights = weights + cv_models[index].get_weights()\n",
    "weights = weights/(K + 1)\n",
    "cv_models[K].set_weights(weights)\n",
    "# 对结果进行预测，作为最终的结果\n",
    "# 进行预测，并且保留对应的数据\n",
    "testA_Y = cv_models[K].predict(testA_X, batch_size=batch_size)\n",
    "testB_Y = cv_models[K].predict(testB_X, batch_size=batch_size)\n",
    "# 和trainning的数据进行对比，检查test数据的合理性\n",
    "print('{}_fold_{} CV model Train Y min {} max {} mean {} std {}'.format(K,index,np.min(train_Y),np.max(train_Y),np.mean(train_Y),np.std(train_Y)))\n",
    "print('{}_fold_{} CV resultA min {} max {} mean {} std {}'.format(K,index,np.min(testA_Y),np.max(testA_Y),np.mean(testA_Y),np.std(testA_Y)))\n",
    "print('{}_fold_{} resultB min {} max {} mean {} std {}'.format(K,index,np.min(testB_Y),np.max(testB_Y),np.mean(testB_Y),np.std(testB_Y)))\n",
    "# 合并数据结果，并且写入测试结果\n",
    "resultA = pd.DataFrame({'ID':raw_testA['ID'].values,'Y':testA_Y.ravel()})\n",
    "resultA.to_csv('resultA_{}_fold_final.csv'.format(K), header=False,index=False)\n",
    "resultB = pd.DataFrame({'ID':raw_testB['ID'].values,'Y':testB_Y.ravel()})\n",
    "resultB.to_csv('resultB_{}_fold_final.csv'.format(K), header=False,index=False)\n",
    "# 最后一次训练没有使用\n",
    "train_loss_mean,val_loss_mean,train_acc_mean,val_acc_mean = 0.,0.,0.,0.\n",
    "# 保留本次模型运行的结果\n",
    "statis = pd.DataFrame(\n",
    "    [[train_loss_mean, val_loss_mean,train_acc_mean,val_acc_mean,np.min(testA_Y),np.max(testA_Y),np.mean(testA_Y),np.std(testA_Y), \\\n",
    "    np.min(testB_Y),np.max(testB_Y),np.mean(testB_Y),np.std(testB_Y),np.min(train_Y),np.max(train_Y),np.mean(train_Y),np.std(train_Y)]],\n",
    "    columns=['train_loss','val_loss','train_acc','val_acc','min_testA_Y','max_testA_Y','testA_Y_mean','test_A_std','min_testB_Y','max_testB_Y','testB_Y_mean','test_B_std',\\\n",
    "             'min_train_Y','max_train_Y','train_Y_mean','train_Y_std'],\n",
    "    index=['model_{}_{}'.format(m['name'],m['batch_size'])])\n",
    "if perf.empty:\n",
    "    perf = statis\n",
    "    print('{}_fold_final CV {}'.format(K,statis))\n",
    "else:\n",
    "    perf = pd.concat([perf,statis])\n",
    "    print('perf {} {}_fold_final statis later added {}'.format(len(perf), K, statis))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.reshape(train_X,(train_X.shape[0],train_X.shape[1],1))\n",
    "valid_X = np.reshape(valid_X,(valid_X.shape[0],valid_X.shape[1],1))\n",
    "testA_X = np.reshape(testA, (testA.shape[0], testB.shape[1], 1))\n",
    "testB_X = np.reshape(testB, (testB.shape[0], testB.shape[1],1))\n",
    "perf = pd.DataFrame()\n",
    "print('Start train on {} models'.format(len(model_array)))\n",
    "for m in model_array:\n",
    "    print('fit in model {}:{} with batch_size {}'.format(m['name'], m['desc'], m['batch_size']))\n",
    "    m['model'].summary()\n",
    "    history = m['model'].fit(\n",
    "        train_X,\n",
    "        train_Y,\n",
    "        epochs = epochs_num,\n",
    "        batch_size = m['batch_size'],\n",
    "        validation_data=(valid_X,valid_Y)\n",
    "    )\n",
    "    # 保存模型\n",
    "    json_string = m['model'].to_json()\n",
    "    f = open('model_{}.json'.format(m['name']),'w')\n",
    "    f.write(json_string)\n",
    "    f.close()\n",
    "    # 保存当前训练的参数\n",
    "    m['model'].save('weights_model_{}_bs_{}.h5'.format(m['name'],m['batch_size']))\n",
    "    #保存history数据\n",
    "    \n",
    "    # 进行预测，并且保留对应的数据\n",
    "    testA_Y = model.predict(testA_X, batch_size=m['batch_size'])\n",
    "    testB_Y = model.predict(testB_X, batch_size=m['batch_size'])\n",
    "    # 和trainning的数据进行对比，检查test数据的合理性\n",
    "    print('Train Y min {} max {} mean {} std {}'.format(np.min(train_Y),np.max(train_Y),np.mean(train_Y),np.std(train_Y)))\n",
    "    print('resultA min {} max {} mean {} std {}'.format(np.min(testA_Y),np.max(testA_Y),np.mean(testA_Y),np.std(testA_Y)))\n",
    "    print('resultB min {} max {} mean {} std {}'.format(np.min(testB_Y),np.max(testB_Y),np.mean(testB_Y),np.std(testB_Y)))\n",
    "    # 合并数据结果，并且写入测试结果\n",
    "    resultA = pd.DataFrame({'ID':raw_testA['ID'].values,'Y':testA_Y.ravel()})\n",
    "    resultA.to_csv('resultA_{}_{}.csv'.format(m['name'],m['batch_size']), header=False,index=False)\n",
    "    resultB = pd.DataFrame({'ID':raw_testB['ID'].values,'Y':testB_Y.ravel()})\n",
    "    resultB.to_csv('resultB_{}_{}.csv'.format(m['name'],m['batch_size']), header=False,index=False)\n",
    "    # 去最后10个poch的平均值作为mean来评价本次模型训练的情况\n",
    "    train_loss_mean = np.mean(history.history['loss'][-11:-1])\n",
    "    val_loss_mean = np.mean(history.history['loss'][-11:-1])\n",
    "    train_acc_mean = np.mean(history.history['mean_absolute_error'])\n",
    "    val_acc_mean = np.mean(history.history['val_mean_absolute_error'])\n",
    "    # 保留本次模型运行的结果\n",
    "    statis = pd.DataFrame(\n",
    "        [[train_loss_mean, val_loss_mean,train_acc_mean,val_acc_mean,np.min(testA_Y),np.max(testA_Y),np.mean(testA_Y),np.std(testA_Y), \\\n",
    "        np.min(testB_Y),np.max(testB_Y),np.mean(testB_Y),np.std(testB_Y),np.min(train_Y),np.max(train_Y),np.mean(train_Y),np.std(train_Y)]],\n",
    "        columns=['train_loss','val_loss','train_acc','val_acc','min_testA_Y','max_testA_Y','testA_Y_mean','test_A_std','min_testB_Y','max_testB_Y','testB_Y_mean','test_B_std',\\\n",
    "                 'min_train_Y','max_train_Y','train_Y_mean','train_Y_std'],\n",
    "        index=['model_{}_{}'.format(m['name'],m['batch_size'])])\n",
    "    if perf.empty:\n",
    "        perf = statis\n",
    "        print('first statis {}'.format(statis))\n",
    "    else:\n",
    "        perf = pd.concat([perf,statis])\n",
    "        print('perf {} statis later added {}'.format(len(perf), statis))\n",
    "    # 将性能信息写入到本地文件\n",
    "    perf.to_excel('models_performance.xlsx')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理train data和test data，让两者的数据更为合理\n",
    "第一步的过程来看，无论是resultA还是resultB中都明显有异常大小的Y值，很明显是对应的testA和testB中的对应数据和train中的数据分布差异造成的。这些差异的来源：\n",
    "- 所有的数据中都有缺失的数据，在数据中表现为0或者NaN值；\n",
    "- 数据差异造成的原因在于：\n",
    " - 对Train数据的处理方式不对，造成数据偏差，从而让学习到的特征有偏差\n",
    " - 部分Test缺失的数据没有被合理地处理，数据本身就有偏差。\n",
    "- 如何处理这些数据是合理的：\n",
    " - 存在一个假设，制造流程中的数据应该是正态分布\n",
    " - 使用正态分布来检查数据的合理性，找到可能有问题的地方\n",
    " \n",
    "### [缺失数据的处理](https://www.slideshare.net/QuantUniversity/missing-data-handling)\n",
    "确实数据的假设，这些假设会决定后续的处理方法\n",
    "- MCAR：missing complete at random\n",
    "- MAR：missing at random\n",
    "- MNAR：missing not at random\n",
    "在实际的工作中经常有各种原因缺失的数据，对于缺失的数据，主要的做法是：\n",
    "- 删除对应的数据\n",
    " - 删除数据行\n",
    " - 删除数据列\n",
    " - 仅删除对应的数据pair\n",
    "- 替换生成对应的数据：根据数据可能的规律假设，生成数据代替缺失的数据\n",
    " - Mean\n",
    " - Condition Mean\n",
    " - Linear Fitting\n",
    " - 。。。\n",
    "\n",
    "### 目前的选择\n",
    "目前的选择情况如下：\n",
    "- 数据量很少，并且test数据也缺数据，所以只能采用生成替换数据的方式\n",
    "- 生成数据是要根据数据的意义以及对应的背景来决定更为合理的方式，这样才有可能不会因为生成数据的不合理带来额外的误差。而在当前环境下并没有对应数据的意义，所以无法依赖这个信息\n",
    "- 基于上述这点，只能做一个假设，制造业中的数据符合normal distribution，使用mean的方式来生成确实数据\n",
    "- 同样的使用mean的方式来检查数据的问题，找到其中存在的大问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用下面代码来找到normalization之后的数据不太匹配的问题\n",
    "```python\n",
    "# 找到array中不超出正态分布的数据以及对应的值\n",
    "def check_standard_scaled_numpy_array(name,normal_arr,data_df,result_arr):\n",
    "    '''\n",
    "    name:被检查的数组的名称\n",
    "    normal_arr:经过normalized的numpy二维数组\n",
    "    data_df:data所对对应的pandas.DataFrame\n",
    "    result_arr:对应数据的Y结果，该结果可以是train数据的实际Y值，也可以是实际的测试\n",
    "    '''\n",
    "    abs_arr = np.abs(normal_arr)\n",
    "    # 检查sigma的值，超出相当的sigma值，说明\n",
    "    idx_arr = np.argwhere(abs_arr > 1.0)\n",
    "    for idx in idx_arr:\n",
    "        print('{} index [{},{}] column {} with value {} normalized value {}  mean {} std {} with Y {}'.format(\n",
    "            name, idx[0],idx[1], data_df.columns.values[idx[1]], data_df.values[idx[0],idx[1]], normal_arr[idx[0],idx[1]],\n",
    "            mean_dict[data_df.columns.values[idx[1]]], std_dict[data_df.columns.values[idx[1]]], result_arr[idx[0]]\n",
    "        ))\n",
    "    # 检查0变量存在的情况\n",
    "    id_arr = np.argwhere(abs_arr > 1.0)\n",
    "    for idx in id_arr:\n",
    "        if normal_arr[idx[0],idx[1]] == 0:\n",
    "            print('zeor checking {} index [{},{}] column {} with value {} normalized {} mean {} std {} with Y {}'.format(\n",
    "            name, idx[0], idx[1], data_df.columns.values[idx[1]], data_df.values[idx[0],idx[1]], normal_arr[idx[0],idx[1]],\n",
    "            mean_dict[data_df.columns.values[idx[1]]], std_dict[data_df.columns.values[idx[1]]], result_arr[idx[0]]\n",
    "        ))\n",
    "                \n",
    "check_standard_scaled_numpy_array('train_data',normalized_train_X,train_X_pd, train_Y_whole)\n",
    "check_standard_scaled_numpy_array('testA',testA, testA_pd, testA_Y)\n",
    "check_standard_scaled_numpy_array('testB',testB, testB_pd, testB_Y)\n",
    "np.savetxt('testA.csv',testA,delimiter=',')\n",
    "np.savetxt('testB.csv',testB,delimiter=',')\n",
    "\n",
    "```\n",
    "    "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用StandardScaler的数据情况\n",
    "从数据可以看到，很多提供的数据不是正态分布的，极端的情况如下：\n",
    "testA index 44 column 312X183 with value 4.9 has 1688849860263937.5 sigma mean 3.4000000000000266 std 4.445339663058968e-16 with Y [  3.51291415e+13]\n",
    "这个的原因是是所有的值都是3.4(500个以上），只有一个值为4.9，std很小导致，导致极端数据的sigma值很大，从而最终预测的时候出现很大的偏差值。这后面有两点：\n",
    "- 为什么会出现如此异常的数据分布：\n",
    " - 数据采集的精度较小导致\n",
    " - 部分操作的环节因为环境的因素有了很大的变化，这个也是可能造成生产偏差的问题。\n",
    "- 处理方法：采用其它的数据normalization方式，比如MinMaxScaler等等\n",
    "## 使用MinMaxScaler的数据情况\n",
    "在test数据上依然有异常的数据，导致test的数据预测出现问题：\n",
    "\n",
    "testB index [30,178] column 210X192 with value 112115.8 normalized value 30301.567567567563  mean 1.4581999999999988 std 0.8153541345510299 with Y [ 1325.29736328]\n",
    "testB index [30,179] column 210X193 with value 595.17 normalized value 1451.6341463414633  mean 0.0706600000000002 std 0.1181985880305888 with Y [ 1325.29736328]\n",
    "testB index [30,180] column 210X194 with value 110676.1 normalized value 40990.88888888888  mean 1.8509018036072138 std 0.6486425340081017 with Y [ 1325.29736328]\n",
    "testB index [30,181] column 210X195 with value 1354.2 normalized value 242.1717352415027  mean 2.849879759519039 std 1.280751217173855 with Y [ 1325.29736328]\n",
    "\n",
    "此处的原始数据也能反映对应的问题\n",
    "![image.png](attachment:image.png)\n",
    "上述部分异常大的数据就是testB中210x192，210x193，210x194的相关数据，这些数据原超其它数据的均值和范围。\n",
    "如何处理该问题：\n",
    "- 先不做相关处理，直接提交对应的数据查看loss函数结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
